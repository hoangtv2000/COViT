{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_model' from 'utils.util' (C:\\Users\\ASUS\\COVID_19\\utils\\util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-887e6b4b2e12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\COVID_19\\trainer\\trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase_trainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot_enc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetricTracker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_predictive_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearly_stopping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'save_model' from 'utils.util' (C:\\Users\\ASUS\\COVID_19\\utils\\util.py)"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "import shutil\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from dataloader.cxr_dataloader import CovidXRDataset\n",
    "\n",
    "from logger.logger import Logger\n",
    "from trainer.trainer import Trainer\n",
    "from utils.util import *\n",
    "\n",
    "from model.modelloader import COVID_PVTv2, COVID_ViT, load_checkpoint\n",
    "\n",
    "from trainer.trainer import Trainer\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Load config\n",
    "config_file = 'config/trainer_config.yml'\n",
    "train_config = OmegaConf.load((os.path.join(cwd, config_file)))['trainer']\n",
    "seeding(train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(config):\n",
    "    train_params = {'batch_size': config.dataloader.train.batch_size,\n",
    "                    'shuffle': True,\n",
    "                    'num_workers': config.dataloader.train.num_workers,\n",
    "                    'pin_memory': True}\n",
    "    \n",
    "    val_params = {'batch_size': config.dataloader.val.batch_size,\n",
    "                  'shuffle': True,\n",
    "                  'num_workers': config.dataloader.val.num_workers,\n",
    "                  'pin_memory': True}\n",
    "\n",
    "    test_params = {'batch_size': config.dataloader.test.batch_size,\n",
    "                   'shuffle': False,\n",
    "                   'num_workers': config.dataloader.test.num_workers}\n",
    "    \n",
    "    print('Name of the dataset:', config.dataset.name)\n",
    "    print('Collected from the description of these github: https://github.com/lindawangg/COVID-Net'\\\n",
    "          , end='\\n{}\\n'.format('-'*50))\n",
    "    \n",
    "    \n",
    "    # Data loader and Generator \n",
    "    train_loader = CovidXRDataset(config = config, mode='train')\n",
    "    val_loader = CovidXRDataset(config = config, mode='val')\n",
    "    # test_loader = CovidXRDataset(config = config, mode='test')\n",
    "    class_dict = train_loader.class_dict\n",
    "\n",
    "    training_generator = DataLoader(train_loader, **train_params)\n",
    "    val_generator = DataLoader(val_loader, **val_params)\n",
    "    # test_generator = DataLoader(test_loader, **test_params)\n",
    "    \n",
    "    print('Load data complete!')\n",
    "    \n",
    "    return training_generator, val_generator, test_generator, class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "     if  name == 'ViT':\n",
    "        return COVID_ViT()\n",
    "     if  name == 'PVT_V2':\n",
    "        return COVID_PVTv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_scheduler_optimizer(model, config):\n",
    "    opt = config['optimizer']['type']\n",
    "    lr = config['optimizer']['lr']\n",
    "    dec = config['optimizer']['weight_decay']\n",
    "    optimizer = None\n",
    "    if (opt == 'AdamW'):\n",
    "        print(\"Use optimizer Adam with lr: \", lr)\n",
    "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=dec)\n",
    "    elif (opt == 'SGD'):\n",
    "        print(\"Use optimizer SGD with lr: \", lr)\n",
    "        optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        \n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=config['scheduler']['scheduler_factor'],\n",
    "                                      patience=config['scheduler']['scheduler_patience'],\n",
    "                                      min_lr=config['scheduler']['scheduler_min_lr'],\n",
    "                                      verbose=config['scheduler']['scheduler_verbose'])\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine(config):\n",
    "    now = datetime.datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H.%M.%S\")\n",
    "    model_name = input(\"Choose model: {model_ViT}, {model_PVT_V2} ? : \")\n",
    "    assert model_name in ['model_ViT', 'model_PVT_V2'], \"You must decleare the model as in description!\"\n",
    "    print('-'*50)\n",
    "        \n",
    "    # Dataset\n",
    "    train_generator, val_generator, _, class_dict = get_dataset(config)\n",
    "    \n",
    "    # Model / Model loader\n",
    "    model = get_model(config[model_name].name)\n",
    "    \n",
    "    #Optimizer\n",
    "    optimizer, scheduler = select_scheduler_optimizer(model, config[model_name])\n",
    "    \n",
    "    # Load model from checkpoint if config load = True\n",
    "    if config.load:\n",
    "        print('----- LOADING CHECKPOINTS -----')\n",
    "        get_checkpoints(config[model_name].name)\n",
    "        checkpoint_name = input(\"Choose one of these checkpoints above: \")\n",
    "        cpkt_fol_name = os.path.join(config.cwd, f'checkpoints/model_{config[model_name].name}/{checkpoint_name}')\n",
    "        \n",
    "        checkpoint_dirmodel = f'{cpkt_fol_name}/model_best_checkpoint.pth'\n",
    "        model, optimizer, scheduler = load_checkpoint(checkpoint_dirmodel, model, optimizer, scheduler)      \n",
    "    else:\n",
    "         # Create new checkpoint\n",
    "        log.info(f\"Checkpoint Folder {cpkt_fol_name} \")\n",
    "        cpkt_fol_name = os.path.join(config.cwd, f'checkpoints/model_{config[model_name].name}/date_{dt_string}')\n",
    "    \n",
    "    # Or create new model\n",
    "    print('----- CREATING NEW MODEL -----')\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    \n",
    "    # Logger\n",
    "    logname = str('LOG_' + config[model_name].name)\n",
    "    log = Logger(path=cpkt_fol_name, name=logname).get_logger()\n",
    "    \n",
    "    log.info(f\"date and time = {dt_string}\")\n",
    "    log.info(f'pyTorch VERSION:{torch.__version__}', )\n",
    "    log.info(f'CUDA VERSION:{torch.version.cuda}')\n",
    "    \n",
    "    # Writer\n",
    "    writer = SummaryWriter('./runs/' + f'model_{config[model_name].name}/date_{dt_string}')\n",
    "\n",
    "    # Device\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and config.cuda) else \"cpu\")\n",
    "\n",
    "    log.info(f'CUDNN VERSION:{torch.backends.cudnn.version()}')\n",
    "    log.info(f'Number CUDA Devices: {torch.cuda.device_count()}') \n",
    "    log.info(f'device: {device}')\n",
    "    \n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(config=config, model=model, optimizer=optimizer,\n",
    "                      data_loader=train_generator, logger=log,\n",
    "                      valid_data_loader=val_generator, class_dict=class_dict,\n",
    "                      lr_scheduler=scheduler,\n",
    "                      checkpoint_dir=cpkt_fol_name)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
